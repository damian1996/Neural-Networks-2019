{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KgBqVtSSn-f"
   },
   "source": [
    "IMPORTS\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41794,
     "status": "ok",
     "timestamp": 1558722260134,
     "user": {
      "displayName": "Klaudia S",
      "photoUrl": "https://lh5.googleusercontent.com/-NoU6CY71EQ0/AAAAAAAAAAI/AAAAAAAAMPo/jTUq_8DBmC4/s64/photo.jpg",
      "userId": "15267701994403312058"
     },
     "user_tz": -120
    },
    "id": "AxzQhD4ASABs",
    "outputId": "cb1adfd6-b7c0-4003-a7fc-bc23d6571ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "import itertools\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "matplotlib.use('Agg') # No pictures displayed \n",
    "%matplotlib inline\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "TRAIN_PATH = '/content/gdrive/My Drive/ptaki/ptaki/train'\n",
    "TEST_PATH = '/content/gdrive/My Drive/ptaki/ptaki/test'\n",
    "MAIN_PATH = '/content/gdrive/My Drive/ptaki/ptaki'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6zR2Oo3SqPg"
   },
   "source": [
    "DATA HELPERS FUNCTIONS\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_smagqdSkNT"
   },
   "outputs": [],
   "source": [
    "def load_log_mel(file_name, start=0, stop=None, n_mels=60):\n",
    "    samples, sample_rate = librosa.core.load(file_name, sr = None)\n",
    "    samples = samples[int(start * sample_rate):int(stop * sample_rate) if stop else None]\n",
    "    spectrogram = librosa.feature.melspectrogram(y = samples, sr = sample_rate,\n",
    "                                                 n_mels = n_mels, fmin = 4000, fmax = 9500)\n",
    "    \n",
    "    log_spec = librosa.core.power_to_db(spectrogram, ref=np.median)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def load_spec(file_name, start=0, stop=None):\n",
    "    sample_rate, samples = wavfile.read(file_name)\n",
    "    samples = samples[int(start * sample_rate):int(stop * sample_rate) if stop else None]\n",
    "    _, _, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def load_test(load_repr=load_log_mel):\n",
    "    with open('sampleSubmission.csv', 'r') as file:\n",
    "        lines = file.read().split()[1:]\n",
    "        sample_ids = [line.split(',')[0] for line in lines]\n",
    "        samples = np.array([s.split('/') for s in sample_ids])\n",
    "    \n",
    "    X_test = []\n",
    "    rec_files = sorted([file_name for file_name in os.listdir('test') \n",
    "                        if file_name.endswith('.wav')], key=lambda x: int(x.split('.')[0][3:]))\n",
    "    for file_name in rec_files:\n",
    "        recording_id = file_name.split('.')[0][3:]\n",
    "        time_markers = samples[samples[:, 0] == recording_id, 1].astype(np.int)\n",
    "        for t in time_markers:\n",
    "            representation = load_repr(os.path.join('test', file_name), start = t, stop = t + 1)\n",
    "            X_test.append(representation)\n",
    "    return np.array(X_test)\n",
    "\n",
    "\n",
    "def read_labels():\n",
    "    labels = []\n",
    "    with open(os.path.join('train', 'labels.txt'), 'r') as file:\n",
    "        text = file.read()\n",
    "        for line in text.split('\\n')[1:]:\n",
    "            if len(line) > 1:\n",
    "                rec, start, stop = line.split(',')\n",
    "                rec, start, stop = int(rec[3:]), float(start), float(stop)\n",
    "                labels.append([rec, start, stop])\n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "def check_voices(second, labels, tol=0.):\n",
    "    return (labels[1] >= second and labels[1] < second + 1 - tol) or \\\n",
    "           (labels[2] < second + 1 and labels[2] > second + tol) or \\\n",
    "           (labels[1] < second and labels[2] > second + 1)\n",
    "\n",
    "\n",
    "def map_seconds_to_y(labels):\n",
    "    y = [0] * 10\n",
    "    y_restrictive = [0] * 10\n",
    "    for s in range(10):\n",
    "        for l in labels:\n",
    "            if check_voices(s, l):\n",
    "                y[s] = 1\n",
    "            if check_voices(s, l, 0.02):\n",
    "                y_restrictive[s] = 1\n",
    "        if y[s] != y_restrictive[s]:\n",
    "            y[s] = -1\n",
    "    return y\n",
    "\n",
    "\n",
    "def load_train(load_repr=load_mel):\n",
    "    labels = read_labels()\n",
    "    X_train, y_train = [], []\n",
    "    rec_files = [file_name for file_name in os.listdir('train') if file_name.endswith('.wav')]\n",
    "    for file_name in rec_files:\n",
    "        recording_id = int(file_name.split('.')[0][3:])\n",
    "        recording_labels = labels[labels[:, 0] == recording_id]\n",
    "        y_binary = map_seconds_to_y(recording_labels)\n",
    "        for i, y in enumerate(y_binary):\n",
    "            if y != -1:\n",
    "                try:\n",
    "                    representation = load_repr(os.path.join('train', file_name), start = i, stop = i + 1)\n",
    "                    X_train.append(representation)\n",
    "                    y_train.append(y)\n",
    "                except ValueError:\n",
    "                    print('Error reading file', file_name)\n",
    "                except TypeError:\n",
    "                    print('Unsupported type', file_name)\n",
    "    return np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJIi9CIjTHWc"
   },
   "source": [
    "READ DATA\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZes069VTHhE"
   },
   "outputs": [],
   "source": [
    "os.chdir(MAIN_PATH)\n",
    "X_test_d = load_test()\n",
    "X_d, y_d = load_train()\n",
    "\n",
    "np.save(os.path.join('train', 'tmp_X_train.pkl'), X_d)\n",
    "np.save(os.path.join('train', 'tmp_y_train.pkl'), y_d)\n",
    "\n",
    "np.save(os.path.join('test', 'tmp_X_test.pkl'), X_test_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUQkeS0icn1j"
   },
   "source": [
    "LOAD DATA\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1036,
     "status": "ok",
     "timestamp": 1558606861684,
     "user": {
      "displayName": "Klaudia S",
      "photoUrl": "https://lh5.googleusercontent.com/-NoU6CY71EQ0/AAAAAAAAAAI/AAAAAAAAMPo/jTUq_8DBmC4/s64/photo.jpg",
      "userId": "15267701994403312058"
     },
     "user_tz": -120
    },
    "id": "nhI8W8uzasjT",
    "outputId": "2538a291-d8ce-40d7-d089-f92badd3396b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589,)\n",
      "(3589, 60, 87)\n",
      "(924, 60, 87)\n"
     ]
    }
   ],
   "source": [
    "X_d = np.load(os.path.join('train', 'tmp_X_train.pkl.npy'))\n",
    "y_d = np.load(os.path.join('train', 'tmp_y_train.pkl.npy'))\n",
    "X_test_d = np.load(os.path.join('test', 'tmp_X_test.pkl.npy'))\n",
    "print(y_d.shape)\n",
    "print(X_d.shape)\n",
    "print(X_test_d.shape)\n",
    "\n",
    "#perm = torch.randperm(y_d.shape[0])\n",
    "#X_d = X_d[perm]\n",
    "#y_d = y_d[perm]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZHyyimdTbaj"
   },
   "source": [
    "MODEL\n",
    "==========\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T83D10egXbb_"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32 * 3 * 5, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        x = self.layer1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        #16, 10, 15\n",
    "        x = x.view(-1, 32 * 3 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return(x)\n",
    "\n",
    "clf = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0pW3XQJUFJE"
   },
   "source": [
    "PREDICTIONS SAVE HELPERS\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vt3gm6NVUCbM"
   },
   "outputs": [],
   "source": [
    "def save_predictions(preds):\n",
    "    with open('sampleSubmission.csv', 'r') as file:\n",
    "        submission_text = file.read().split()\n",
    "        header = submission_text[0]\n",
    "        lines = submission_text[1:]\n",
    "\n",
    "    output_lines = [header]\n",
    "    for pred, line in zip(preds, lines):\n",
    "        output_lines.append(\"{},{}\".format(line.split(',')[0], pred))\n",
    "    \n",
    "    with open('mySubmission.csv', 'w') as file:\n",
    "        file.write('\\n'.join(output_lines) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiLOsWbRRlsf"
   },
   "source": [
    "Model to use in VotingClassifier\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YHX9kwnRlPW"
   },
   "outputs": [],
   "source": [
    "class CNN_Wrapper:\n",
    "    \n",
    "    def __init__(self, idx, pretrained, path):\n",
    "        print(idx, pretrained, path)\n",
    "        self.idx = idx\n",
    "        self.clf = SimpleCNN()\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.clf.parameters())\n",
    "        self.epochs = 25\n",
    "        self.serialize_path = path if path else f'saved_model/{self.idx}.pkl'\n",
    "        self.batch_size = 64\n",
    "        self.pretrained = pretrained\n",
    "        print(self.idx, self.pretrained)\n",
    "    \n",
    "    def build_loaders(self, X, y):\n",
    "        split_point = int(len(X) * 0.8)\n",
    "\n",
    "        X_train = torch.Tensor(X[:split_point])\n",
    "        y_train = torch.LongTensor(y[:split_point])\n",
    "\n",
    "        X_valid = torch.Tensor(X[split_point:])\n",
    "        y_valid = torch.LongTensor(y[split_point:])\n",
    "\n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        data_loader = DataLoader(dataset, self.batch_size, shuffle = True)\n",
    "\n",
    "        valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "        valid_data_loader = DataLoader(valid_dataset, self.batch_size)\n",
    "        \n",
    "        return data_loader, valid_data_loader, y_valid\n",
    "    \n",
    "    def fit(self, XX, yy):\n",
    "        if self.pretrained:\n",
    "            print(\"This model has already pretrained\")\n",
    "            return\n",
    "        data_loader, valid_data_loader, y_valid = self.build_loaders(XX, yy)\n",
    "        \n",
    "        best_preds, best_score = None, 0.\n",
    "        losses, scores = [], []\n",
    "        best_auc = 0.\n",
    "        for epoch in trange(self.epochs):\n",
    "            running_loss = 0\n",
    "            self.clf.train()\n",
    "            for X, y in data_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.clf(X)\n",
    "                loss = self.criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            losses.append(running_loss)\n",
    "\n",
    "            self.clf.eval()\n",
    "            preds = []\n",
    "            for X, _ in valid_data_loader:\n",
    "                out = self.clf(X)\n",
    "                preds.append(torch.softmax(out, dim = 1)[:, 1].detach().numpy())\n",
    "            preds = np.concatenate(preds, axis = 0)\n",
    "\n",
    "            # Metryką testującą jest ROC AUC\n",
    "            score = roc_auc_score(y_valid.numpy(), preds)\n",
    "            scores.append(score)\n",
    "            #print(f\"AUC score = {score}\")\n",
    "            best_auc = max(best_auc, score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_preds = preds\n",
    "                #np.save('tmp_preds', best_preds)\n",
    "\n",
    "                # Model dający najlepszy wynik powinien być zapisany\n",
    "                torch.save(self.clf.state_dict(), self.serialize_path)\n",
    "        \n",
    "        print(f\"Model {self.idx} had AUC = {best_auc}\")\n",
    "        self.plot(scores, losses)\n",
    "        \n",
    "    \n",
    "    def plot(self, scores, losses):\n",
    "        print(f\"Results for {self.idx} model\")\n",
    "        plt.plot(scores)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(losses)\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.clf.load_state_dict(torch.load(self.serialize_path))\n",
    "\n",
    "        X_test_tensor = torch.Tensor(X_test)\n",
    "\n",
    "        test_dataset = TensorDataset(X_test_tensor)\n",
    "        test_data_loader = DataLoader(test_dataset, batch_size = self.batch_size)\n",
    "\n",
    "        self.clf.eval()\n",
    "        preds = []\n",
    "        zeros, ones = 0, 0\n",
    "        for X in test_data_loader:\n",
    "            out = self.clf(X[0])\n",
    "\n",
    "            bools_0 = torch.nonzero(out[:, 0] > out[:, 1]).size(0)\n",
    "            bools_1 = torch.nonzero(out[:, 0] < out[:, 1]).size(0)\n",
    "            zeros, ones = zeros + bools_0, ones + bools_1\n",
    "\n",
    "            preds.append(torch.softmax(out, dim = 1)[:, 1].detach().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, axis = 0)\n",
    "        print(zeros, ones)\n",
    "\n",
    "        #save_predictions(preds)\n",
    "        return preds\n",
    "      \n",
    "    def fitting_on_validation(valid_data_loader):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcVCdq30VrjH"
   },
   "source": [
    "VOTING CLASSIFIER\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQxZ_droVr9T"
   },
   "outputs": [],
   "source": [
    "class VotingClassifier:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.models_cnt = len(models)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for i, model in enumerate(self.models):\n",
    "            print(f\"Starting Model {i+1}\")\n",
    "            model.fit(X, y)\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        all_labels = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            print(f\"Predicting Model {i}\")\n",
    "            predictions = model.predict(X_test)\n",
    "            all_labels.append(predictions)\n",
    "        return all_labels\n",
    "    \n",
    "    def voting(self, labels):\n",
    "        full_mean_result = torch.zeros(labels[0].shape)\n",
    "        for i, lab in enumerate(labels):\n",
    "            full_mean_result = full_mean_result + torch.FloatTensor(lab)\n",
    "        \n",
    "        final_labels = full_mean_result/len(labels)\n",
    "        save_predictions(final_labels)\n",
    "        print(final_labels)\n",
    "        return final_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fmrb4d5CfgMc"
   },
   "source": [
    "GENERATING RESULTS\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFR0C6JHGxZX"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "n_models = 30\n",
    "pretrained = [False] * n_models #, False, False, False, False]\n",
    "paths = [None] * n_models # None, None, None, None]\n",
    "models = [CNN_Wrapper(i+1, pretrained[i], paths[i]) for i in range(n_models)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6QuC_yblyT-"
   },
   "outputs": [],
   "source": [
    "p_1 = f'saved_model/30.pkl'\n",
    "p_2 = f'saved_model/23.pkl'\n",
    "p_3 = f'saved_model/22.pkl'\n",
    "p_4 = f'saved_model/18.pkl'\n",
    "p_5 = f'saved_model/17.pkl'\n",
    "p_6 = f'saved_model/2.pkl'\n",
    "p_7 = f'saved_model/16.pkl'\n",
    "p_8 = f'saved_model/24.pkl'\n",
    "p_9 = f'saved_model/12.pkl'\n",
    "p_10 = f'saved_model/21.pkl'\n",
    "\n",
    "n_models = 10\n",
    "pretrained = [True] * n_models #, False, False, False, False]\n",
    "paths = [p_1, p_2, p_3, p_4, p_5, p_6, p_7, p_8, p_9, p_10] # None, None, None, None]\n",
    "models = [CNN_Wrapper(i+1, pretrained[i], paths[i]) for i in range(n_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQiBJayP3LRg"
   },
   "outputs": [],
   "source": [
    "vot_clf = VotingClassifier(models)\n",
    "vot_clf.fit(X_d, y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5849,
     "status": "ok",
     "timestamp": 1558613378392,
     "user": {
      "displayName": "Klaudia S",
      "photoUrl": "https://lh5.googleusercontent.com/-NoU6CY71EQ0/AAAAAAAAAAI/AAAAAAAAMPo/jTUq_8DBmC4/s64/photo.jpg",
      "userId": "15267701994403312058"
     },
     "user_tz": -120
    },
    "id": "343HZ3O69aW8",
    "outputId": "8e9e687d-1bf4-4951-e334-4b9a21a8ec28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model 0\n",
      "569 355\n",
      "Predicting Model 1\n",
      "601 323\n",
      "Predicting Model 2\n",
      "605 319\n",
      "Predicting Model 3\n",
      "585 339\n",
      "Predicting Model 4\n",
      "583 341\n",
      "Predicting Model 5\n",
      "620 304\n",
      "Predicting Model 6\n",
      "679 245\n",
      "Predicting Model 7\n",
      "595 329\n",
      "Predicting Model 8\n",
      "636 288\n",
      "Predicting Model 9\n",
      "669 255\n",
      "tensor([0.0889, 0.0445, 0.0345, 0.1038, 0.0235, 0.1961, 0.5394, 0.0326, 0.0661,\n",
      "        0.0292, 0.1168, 0.0456, 0.0295, 0.2616, 0.2942, 0.6644, 0.2530, 0.0593,\n",
      "        0.7757, 0.0957, 0.1732, 0.1001, 0.6603, 0.0982, 0.8359, 0.2169, 0.0796,\n",
      "        0.2154, 0.0159, 0.0198, 0.0565, 0.0658, 0.9430, 0.7084, 0.0275, 0.9748,\n",
      "        0.2099, 0.7832, 0.9505, 0.0454, 0.9463, 0.9695, 0.4290, 0.4643, 0.0985,\n",
      "        0.0255, 0.1958, 0.0719, 0.1389, 0.9478, 0.1194, 0.1755, 0.3084, 0.0518,\n",
      "        0.4186, 0.0235, 0.3319, 0.0639, 0.0542, 0.0462, 0.0349, 0.8406, 0.0221,\n",
      "        0.7208, 0.2527, 0.0251, 0.0897, 0.0579, 0.6456, 0.3190, 0.0632, 0.0885,\n",
      "        0.0368, 0.4588, 0.2124, 0.0540, 0.0343, 0.0202, 0.0192, 0.0370, 0.1028,\n",
      "        0.0690, 0.0558, 0.0544, 0.5654, 0.0769, 0.0115, 0.1520, 0.1947, 0.0584,\n",
      "        0.0485, 0.0130, 0.7785, 0.0644, 0.8116, 0.8443, 0.7336, 0.0730, 0.9948,\n",
      "        0.0134, 0.0345, 0.0410, 0.0440, 0.3652, 0.1329, 0.0845, 0.0245, 0.9360,\n",
      "        0.1293, 0.1497, 0.0292, 0.0218, 0.7150, 0.0479, 0.1502, 0.2726, 0.7176,\n",
      "        0.3051, 0.0348, 0.0678, 0.0393, 0.1116, 0.0264, 0.2532, 0.0287, 0.0676,\n",
      "        0.1145, 0.0987, 0.1425, 0.0821, 0.0965, 0.8416, 0.4569, 0.0913, 0.9935,\n",
      "        0.0932, 0.0066, 0.0852, 0.0936, 0.6611, 0.2692, 0.6505, 0.0429, 0.0353,\n",
      "        0.8302, 0.5078, 0.6320, 0.0073, 0.0246, 0.9296, 0.8888, 0.6843, 0.8077,\n",
      "        0.8280, 0.9882, 0.0605, 0.0505, 0.5879, 0.9682, 0.8856, 0.7289, 0.0156,\n",
      "        0.7535, 0.9756, 0.1046, 0.8484, 0.6425, 0.5647, 0.0792, 0.9963, 0.7316,\n",
      "        0.0552, 0.9910, 0.9946, 0.9741, 0.9589, 0.4725, 0.0150, 0.6384, 0.0985,\n",
      "        0.0187, 0.1353, 0.0267, 0.1267, 0.0373, 0.0308, 0.0512, 0.1337, 0.0354,\n",
      "        0.1021, 0.0491, 0.6025, 0.2553, 0.0323, 0.7349, 0.0584, 0.0484, 0.8311,\n",
      "        0.0709, 0.1323, 0.5643, 0.9822, 0.2670, 0.6585, 0.7955, 0.0174, 0.5205,\n",
      "        0.0729, 0.6789, 0.0391, 0.9899, 0.1725, 0.0300, 0.6622, 0.0310, 0.1094,\n",
      "        0.5466, 0.0472, 0.0901, 0.1958, 0.1138, 0.2260, 0.0723, 0.8334, 0.0235,\n",
      "        0.0109, 0.0683, 0.0223, 0.5417, 0.0189, 0.9258, 0.0813, 0.0219, 0.3383,\n",
      "        0.0845, 0.5138, 0.1936, 0.0366, 0.0384, 0.6899, 0.3576, 0.3718, 0.1697,\n",
      "        0.6298, 0.2480, 0.4295, 0.2477, 0.4764, 0.1995, 0.5460, 0.5323, 0.0522,\n",
      "        0.5601, 0.2497, 0.1386, 0.5310, 0.7045, 0.4709, 0.5784, 0.1881, 0.5306,\n",
      "        0.2301, 0.6560, 0.0568, 0.0682, 0.1389, 0.1404, 0.1228, 0.6292, 0.3937,\n",
      "        0.1176, 0.5302, 0.1445, 0.2582, 0.2075, 0.4030, 0.4863, 0.2639, 0.8484,\n",
      "        0.3115, 0.0943, 0.2515, 0.7257, 0.3385, 0.3214, 0.3150, 0.0591, 0.2743,\n",
      "        0.6376, 0.0659, 0.1338, 0.0205, 0.7511, 0.4338, 0.1088, 0.4874, 0.4898,\n",
      "        0.1461, 0.5510, 0.0749, 0.0828, 0.0561, 0.1329, 0.1835, 0.0150, 0.5502,\n",
      "        0.1632, 0.2434, 0.0115, 0.0272, 0.0697, 0.0171, 0.0785, 0.0131, 0.0278,\n",
      "        0.0294, 0.0182, 0.0266, 0.0466, 0.0145, 0.0108, 0.1591, 0.0293, 0.0135,\n",
      "        0.0087, 0.0247, 0.0449, 0.1360, 0.0292, 0.0296, 0.0151, 0.0345, 0.0335,\n",
      "        0.0297, 0.0745, 0.9783, 0.9263, 0.6937, 0.9668, 0.2821, 0.3443, 0.2718,\n",
      "        0.0262, 0.0833, 0.2222, 0.1015, 0.7923, 0.7103, 0.9997, 0.9967, 0.8329,\n",
      "        0.1261, 0.6552, 0.9962, 0.9837, 0.9225, 0.9854, 0.9939, 0.9408, 0.9991,\n",
      "        0.1457, 0.0708, 0.9612, 0.8460, 0.8865, 0.8908, 0.3725, 0.0385, 0.9574,\n",
      "        0.9003, 0.7761, 0.6182, 0.6264, 0.1341, 0.5891, 0.0623, 0.7024, 0.0492,\n",
      "        0.7724, 0.9980, 0.9826, 0.9829, 0.9691, 0.9293, 0.9775, 0.9985, 0.7528,\n",
      "        0.9719, 0.9898, 0.9117, 0.3774, 0.9870, 0.9814, 0.8758, 0.6135, 0.9093,\n",
      "        0.8837, 0.9631, 0.2295, 0.3088, 0.1979, 0.1946, 0.7744, 0.3529, 0.8750,\n",
      "        0.9104, 0.0693, 0.0381, 0.0491, 0.7179, 0.3932, 0.7455, 0.0867, 0.9763,\n",
      "        0.0271, 0.1666, 0.2536, 0.8691, 0.5630, 0.9810, 0.9542, 0.4650, 0.0325,\n",
      "        0.1186, 0.2647, 0.0943, 0.1350, 0.7452, 0.0224, 0.0450, 0.1368, 0.1783,\n",
      "        0.2054, 0.7680, 0.9238, 0.0437, 0.0563, 0.9865, 0.0348, 0.9261, 0.1007,\n",
      "        0.9908, 0.9958, 0.8497, 0.8629, 0.8270, 0.5398, 0.7329, 0.2555, 0.1074,\n",
      "        0.9763, 0.0582, 0.0269, 0.8842, 0.7472, 0.9333, 0.1057, 0.0410, 0.0799,\n",
      "        0.2964, 0.0640, 0.0401, 0.0429, 0.2496, 0.1499, 0.0767, 0.0823, 0.8832,\n",
      "        0.9692, 0.3182, 0.3511, 0.9677, 0.0377, 0.1001, 0.2364, 0.0971, 0.0658,\n",
      "        0.2331, 0.8157, 0.0658, 0.0592, 0.8914, 0.9637, 0.9996, 0.9642, 0.8443,\n",
      "        0.9943, 0.0570, 0.9407, 0.8134, 0.9996, 0.1455, 0.1390, 0.6341, 0.1831,\n",
      "        0.1633, 0.2223, 0.2363, 0.9743, 0.4666, 0.6671, 0.9731, 0.1083, 0.9820,\n",
      "        0.4798, 0.4449, 0.9120, 0.8978, 0.9654, 0.9894, 0.0525, 0.8889, 0.1328,\n",
      "        0.8467, 0.0586, 0.9466, 0.5788, 0.1237, 0.1199, 0.9132, 0.1785, 0.2319,\n",
      "        0.1156, 0.3268, 0.0501, 0.9443, 0.1074, 0.0342, 0.1837, 0.2173, 0.0796,\n",
      "        0.0784, 0.2546, 0.7706, 0.9081, 0.4284, 0.0983, 0.9811, 0.8753, 0.0548,\n",
      "        0.0167, 0.0935, 0.0428, 0.1485, 0.0905, 0.0348, 0.4865, 0.1270, 0.0663,\n",
      "        0.0894, 0.7957, 0.7293, 0.1528, 0.9934, 0.7350, 0.0767, 0.0444, 0.1298,\n",
      "        0.9697, 0.9939, 0.1138, 0.9135, 0.0879, 0.9872, 0.0129, 0.7899, 0.0893,\n",
      "        0.0632, 0.9357, 0.9357, 0.1507, 0.1254, 0.2214, 0.3280, 0.2715, 0.9492,\n",
      "        0.9959, 0.8323, 0.7078, 0.0353, 0.9834, 0.1918, 0.4100, 0.0873, 0.1254,\n",
      "        0.0194, 0.1511, 0.9387, 0.8822, 0.9942, 0.9551, 0.6897, 0.9176, 0.8071,\n",
      "        0.0291, 0.9124, 0.0840, 0.8227, 0.9361, 0.8643, 0.9984, 0.0684, 0.7080,\n",
      "        0.7853, 0.9139, 0.9672, 0.9831, 0.8306, 0.8223, 0.4641, 0.0730, 0.1502,\n",
      "        0.1642, 0.9739, 0.9212, 0.0942, 0.9751, 0.0598, 0.0218, 0.9967, 0.9989,\n",
      "        0.9740, 0.9964, 0.9935, 0.9996, 0.9717, 0.8965, 0.9910, 0.0601, 0.0557,\n",
      "        0.0117, 0.0538, 0.0834, 0.1597, 0.8455, 0.9494, 0.1683, 0.1638, 0.2960,\n",
      "        0.9831, 0.2337, 0.6973, 0.0188, 0.1388, 0.2172, 0.4796, 0.5324, 0.9984,\n",
      "        0.1141, 0.7375, 0.1174, 0.4998, 0.0347, 0.9974, 0.9491, 0.2791, 0.0367,\n",
      "        0.0304, 0.2383, 0.1820, 0.3934, 0.1981, 0.0669, 0.1698, 0.0478, 0.8785,\n",
      "        0.9296, 0.9386, 0.9595, 0.0809, 0.1842, 0.7003, 0.6615, 0.1340, 0.3763,\n",
      "        0.0358, 0.0701, 0.0309, 0.9911, 0.7481, 0.1249, 0.1197, 0.3353, 0.1779,\n",
      "        0.9851, 0.5669, 0.9847, 0.0424, 0.9655, 0.9346, 0.9932, 0.9766, 0.0419,\n",
      "        0.0582, 0.1854, 0.9461, 0.8589, 0.8861, 0.9528, 0.0899, 0.8199, 0.1718,\n",
      "        0.1147, 0.0192, 0.7354, 0.9478, 0.0192, 0.0623, 0.0232, 0.3019, 0.0633,\n",
      "        0.5683, 0.0981, 0.1323, 0.1219, 0.8169, 0.9987, 0.0501, 0.0261, 0.0611,\n",
      "        0.1862, 0.8262, 0.6657, 0.0038, 0.1076, 0.0862, 0.0595, 0.1715, 0.0701,\n",
      "        0.0737, 0.0964, 0.1435, 0.0503, 0.0870, 0.0733, 0.0651, 0.0666, 0.2501,\n",
      "        0.0647, 0.1289, 0.0538, 0.0940, 0.0620, 0.0872, 0.0535, 0.0820, 0.0461,\n",
      "        0.0635, 0.1804, 0.0685, 0.0525, 0.1126, 0.0620, 0.5969, 0.0959, 0.1176,\n",
      "        0.1422, 0.0751, 0.1156, 0.0816, 0.5969, 0.0789, 0.0868, 0.1004, 0.1267,\n",
      "        0.1041, 0.1243, 0.0713, 0.0673, 0.0480, 0.0547, 0.0689, 0.1253, 0.0869,\n",
      "        0.1481, 0.1357, 0.1739, 0.1998, 0.0956, 0.1084, 0.1078, 0.0681, 0.0417,\n",
      "        0.0540, 0.0875, 0.1034, 0.0913, 0.0792, 0.1146, 0.1845, 0.0906, 0.0781,\n",
      "        0.1014, 0.3435, 0.0975, 0.1177, 0.1742, 0.0526, 0.1010, 0.9769, 0.0432,\n",
      "        0.0084, 0.0278, 0.1108, 0.6954, 0.0424, 0.0621, 0.0803, 0.1787, 0.0903,\n",
      "        0.8486, 0.0393, 0.0662, 0.0326, 0.9013, 0.1534, 0.0530, 0.1468, 0.0252,\n",
      "        0.0236, 0.0304, 0.0247, 0.0207, 0.2632, 0.0520, 0.9711, 0.0962, 0.0313,\n",
      "        0.1493, 0.5273, 0.0652, 0.6180, 0.0696, 0.1081, 0.0472, 0.9882, 0.0640,\n",
      "        0.9154, 0.0651, 0.9612, 0.9720, 0.0840, 0.0577, 0.0500, 0.0944, 0.0139,\n",
      "        0.1004, 0.9865, 0.0161, 0.0418, 0.8595, 0.0895, 0.0898, 0.0763, 0.0485,\n",
      "        0.1951, 0.0183, 0.9598, 0.0466, 0.0451, 0.0715, 0.0423, 0.1744, 0.0633,\n",
      "        0.1777, 0.0824, 0.0681, 0.0536, 0.0529, 0.9911, 0.5938, 0.0412, 0.0209,\n",
      "        0.1218, 0.2291, 0.0140, 0.0215, 0.0536, 0.1323, 0.1274, 0.1491, 0.0677,\n",
      "        0.9796, 0.0436, 0.4180, 0.1462, 0.0886, 0.8797, 0.9648, 0.0706, 0.8466,\n",
      "        0.0535, 0.0439, 0.1719, 0.0228, 0.0327, 0.7432, 0.1404, 0.1429, 0.1021,\n",
      "        0.0983, 0.8217, 0.9147, 0.4118, 0.9972, 0.7846, 0.2601, 0.0570, 0.0104,\n",
      "        0.0980, 0.0461, 0.0572, 0.9743, 0.2924, 0.1786, 0.0636, 0.9877, 0.0382,\n",
      "        0.0799, 0.0942, 0.1036, 0.0923, 0.9177, 0.0425])\n"
     ]
    }
   ],
   "source": [
    "labels = vot_clf.predict(X_test_d)\n",
    "final_labels = vot_clf.voting(labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinalModel.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
