{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLiHn1VVO5So"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26344,
     "status": "ok",
     "timestamp": 1561206970387,
     "user": {
      "displayName": "Klaudia S",
      "photoUrl": "https://lh5.googleusercontent.com/-NoU6CY71EQ0/AAAAAAAAAAI/AAAAAAAAMPo/jTUq_8DBmC4/s64/photo.jpg",
      "userId": "15267701994403312058"
     },
     "user_tz": -120
    },
    "id": "BrZvHBmUOZpR",
    "outputId": "6fdd394c-0c82-4559-c408-c67df17e3aa2"
   },
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "from google.colab import widgets\n",
    "import os\n",
    "import argparse\n",
    "from torch import LongTensor, FloatTensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import re\n",
    "import string\n",
    "import unicodedata \n",
    "import os\n",
    "import codecs\n",
    "import random\n",
    "import logging\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from collections import Counter, defaultdict\n",
    "from easydict import EasyDict as edict\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "path_to_folder = '/content/gdrive/My Drive/'\n",
    "noise_dir = os.path.join(path_to_folder, 'noise')\n",
    "data_dir = os.path.join(noise_dir, 'ujnn2019')\n",
    "checkpoint_path = os.path.join(data_dir, 'checkpoint.pkl')\n",
    "results_path = os.path.join(data_dir, 'test.out')\n",
    "\n",
    "!mkdir -p checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Nn8M-43O_sH"
   },
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6etIysOjP1Uf"
   },
   "outputs": [],
   "source": [
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdUqbXPxe6WT"
   },
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, clean_dir, distorted_dir, siz, transform=None):\n",
    "        self.clean_dir = clean_dir\n",
    "        self.dist_dir = distorted_dir\n",
    "        self.siz = siz\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx + 1\n",
    "        #clean_img = Image.open(os.path.join(self.clean_dir, f'{idx}.jpg'))\n",
    "        #dist_img = Image.open(os.path.join(self.dist_dir, f'{idx}.jpg'))\n",
    "        \n",
    "        with open(os.path.join(self.dist_dir, f'{idx}.jpg'), 'rb') as f:\n",
    "            dist_img = Image.open(f)\n",
    "            transformed_dist = self.transform(dist_img)\n",
    "        \n",
    "        with open(os.path.join(self.clean_dir, f'{idx}.jpg'), 'rb') as f:\n",
    "            clean_img = Image.open(f)\n",
    "            transformed_clean = self.transform(clean_img)\n",
    "\n",
    "        return (transformed_clean, transformed_dist)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.siz\n",
    "\n",
    "class ValidDataset2(Dataset):\n",
    "    def __init__(self, clean_dir, distorted_dir, siz, transform=None):\n",
    "        self.clean_dir = clean_dir\n",
    "        self.dist_dir = distorted_dir\n",
    "        self.siz = siz\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx + (10000 - self.siz) + 1\n",
    "        #clean_img = Image.open(os.path.join(self.clean_dir, f'{idx}.jpg'))\n",
    "        #dist_img = Image.open(os.path.join(self.dist_dir, f'{idx}.jpg'))\n",
    "        \n",
    "        with open(os.path.join(self.dist_dir, f'{idx}.jpg'), 'rb') as f:\n",
    "            dist_img = Image.open(f)\n",
    "            transformed_dist = self.transform(dist_img)\n",
    "        \n",
    "        with open(os.path.join(self.clean_dir, f'{idx}.jpg'), 'rb') as f:\n",
    "            clean_img = Image.open(f)\n",
    "            transformed_clean = self.transform(clean_img)\n",
    "\n",
    "        return (transformed_clean, transformed_dist)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.siz\n",
    "      \n",
    "class TestDataset2(Dataset):\n",
    "    def __init__(self, test_dir, transform):\n",
    "        self.test_dir = test_dir\n",
    "        self.siz = 400\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx + 1\n",
    "        #test_img = Image.open(os.path.join(test_dir, f'{idx}.jpg'))\n",
    "        with open(os.path.join(test_dir, f'{idx}.jpg'), 'rb') as f:\n",
    "            test_img = Image.open(f)\n",
    "            transformed_test = self.transform(test_img)\n",
    "        \n",
    "        return transformed_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.siz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnrobwHa7VKl"
   },
   "source": [
    "# Full RAM datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6nPhB8y7VXm"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, clean, distorted, transform=None):\n",
    "        self.clean = clean\n",
    "        self.distorted = distorted\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        clean_ex = self.clean[idx]\n",
    "        #clean_ex = min_max_normalization(clean_ex, 0, 1)\n",
    "        dist_ex = self.distorted[idx]\n",
    "        #dist_ex = min_max_normalization(dist_ex, 0, 1)\n",
    "        return (clean_ex, dist_ex)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.clean.shape[0]\n",
    "\n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, clean, distorted, transform=None):\n",
    "        self.clean = clean\n",
    "        self.distorted = distorted\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #clean_ex = self.transform(self.clean[idx])\n",
    "        #dist_ex = self.transform(self.distorted[idx])\n",
    "        clean_ex = self.clean[idx]\n",
    "        #clean_ex = min_max_normalization(clean_ex, 0, 1)\n",
    "        dist_ex = self.distorted[idx]\n",
    "        #dist_ex = min_max_normalization(dist_ex, 0, 1)\n",
    "        return (clean_ex, dist_ex)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.clean.shape[0]\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, distorted, transform=None):\n",
    "        self.distorted = distorted\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #dist_ex = self.transform(self.distorted[idx])\n",
    "        dist_ex = self.distorted[idx]\n",
    "        return dist_ex\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.distorted.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4dmZo93O73T"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ontJV-S4BsYc"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda tensor: tensor.view(48*48*3))\n",
    "])\n",
    "\n",
    "def get_clean_and_distorted_examples():\n",
    "    clean_dir = os.path.join(data_dir, 'clean')\n",
    "    dist_dir = os.path.join(data_dir, 'distorted')\n",
    "    \n",
    "    clean_files = os.listdir(clean_dir)\n",
    "    dist_files = os.listdir(dist_dir)\n",
    "    \n",
    "    clean_images, dist_images = [], []\n",
    "    for file_id, filename in enumerate(clean_files):\n",
    "        #if file_id == 10: break\n",
    "        if file_id % 10 == 0: print(file_id)\n",
    "        with open(os.path.join(clean_dir, filename), 'rb') as f:\n",
    "            clean_img = Image.open(f)\n",
    "            transformed_clean = transform(clean_img)\n",
    "            clean_images.append(transformed_clean)\n",
    "    \n",
    "    for file_id, filename in enumerate(dist_files):\n",
    "        if file_id % 10 == 0: print(file_id)\n",
    "        #if file_id == 10: break\n",
    "        with open(os.path.join(dist_dir, filename), 'rb') as f:\n",
    "            dist_img = Image.open(f)\n",
    "            transformed_dist = transform(dist_img)\n",
    "            dist_images.append(transformed_dist)\n",
    "    \n",
    "    clean_tensor, dist_tensor = torch.stack(clean_images), torch.stack(dist_images)\n",
    "    return clean_tensor, dist_tensor\n",
    "    \n",
    "def get_test_examples():\n",
    "    test_dir = os.path.join(data_dir, 'test_distorted')\n",
    "    test_files = os.listdir(test_dir)\n",
    "    test_images = []\n",
    "    \n",
    "    for filename in test_files:\n",
    "        with open(os.path.join(test_dir, filename), 'rb') as f:\n",
    "            test_images.append(transform(Image.open(f)))\n",
    "    return torch.stack(test_images)\n",
    "    \n",
    "def create_train_and_valid_datasets(data):\n",
    "    split_point = 9000\n",
    "    train, valid = data[:split_point], data[split_point:]\n",
    "    return train, valid\n",
    "    \n",
    "def get_training_dataset():\n",
    "    clean_dir = os.path.join(data_dir, 'clean')\n",
    "    distorted_dir = os.path.join(data_dir, 'distorted')\n",
    "    #transforms.Lambda(lambda tensor: tensor.view(784))\n",
    "    dataset = TrainDataset2(clean_dir, distorted_dir, 9000, transform)\n",
    "    return dataset\n",
    "\n",
    "def get_valid_dataset():\n",
    "    clean_dir = os.path.join(data_dir, 'clean')\n",
    "    distorted_dir = os.path.join(data_dir, 'distorted')\n",
    "    #transforms.Lambda(lambda tensor: tensor.view(784))\n",
    "    dataset = ValidDataset2(clean_dir, distorted_dir, 1000, transform)\n",
    "    return dataset  \n",
    "\n",
    "def get_testing_dataset():\n",
    "    test_dir = os.path.join(data_dir, 'test_distorted')\n",
    "    dataset = TestDataset2(test_dir, transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqpZNcwNO4jD"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(args, shuffle, clean, dist, test_data):    \n",
    "    clean_train, clean_valid = create_train_and_valid_datasets(clean)\n",
    "    dist_train, dist_valid = create_train_and_valid_datasets(dist)\n",
    "    \n",
    "    train_dataset = TrainDataset(clean_train, dist_train)\n",
    "    valid_dataset = ValidDataset(clean_valid, dist_valid)\n",
    "    test_dataset = TestDataset(test_data)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=args.train_batch_size,\n",
    "            num_workers=1,\n",
    "            shuffle=shuffle\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "            dataset=valid_dataset,\n",
    "            batch_size = args.train_batch_size,\n",
    "            num_workers=1,\n",
    "            shuffle=shuffle\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            dataset=test_dataset,\n",
    "            batch_size=args.test_batch_size,\n",
    "            num_workers=1,\n",
    "            shuffle=not shuffle)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3u8qQp4PJaL"
   },
   "source": [
    " # Averaged metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "giTiAnhrPI6C"
   },
   "outputs": [],
   "source": [
    "# EXPONENTIALLY DECAYED MOVING AVERAGE \n",
    "class AverageBase(object):\n",
    "    def __init__(self, value=0):\n",
    "        self.value = float(value) if value is not None else None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(round(self.value, 4))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.value\n",
    "    \n",
    "    def __format__(self, fmt):\n",
    "        return self.value.__format__(fmt)\n",
    "    \n",
    "    def __float__(self):\n",
    "        return self.value\n",
    "    \n",
    "\n",
    "class RunningAverage(AverageBase):\n",
    "    \"\"\"\n",
    "    Keeps track of a cumulative moving average (CMA).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, value=0, count=0):\n",
    "        super(RunningAverage, self).__init__(value)\n",
    "        self.count = count\n",
    "        \n",
    "    def update(self, value):\n",
    "        self.value = (self.value * self.count + float(value))\n",
    "        self.count += 1\n",
    "        self.value /= self.count\n",
    "        return self.value\n",
    "\n",
    "\n",
    "class MovingAverage(AverageBase):\n",
    "    \"\"\"\n",
    "    An exponentially decaying moving average (EMA).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.99):\n",
    "        super(MovingAverage, self).__init__(None)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def update(self, value):\n",
    "        if self.value is None:\n",
    "            self.value = float(value)\n",
    "        else:\n",
    "            self.value = self.alpha * self.value + (1 - self.alpha) * float(value)\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVAmSYmJPMVM"
   },
   "source": [
    "# Data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7tKOYrH0PMc_"
   },
   "outputs": [],
   "source": [
    "def data_preview(dataset):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    sample = dataset.train_data[:64]\n",
    "    # shape (64, 28, 28)\n",
    "    sample = sample.reshape(8,8,28,28)\n",
    "    # shape (8, 8, 28, 28)\n",
    "    sample = sample.permute(0,2,1,3)\n",
    "    # shape (8, 28, 8, 28)\n",
    "    sample = sample.reshape(8*28,8*28)\n",
    "    # shape (8*28, 8*28)\n",
    "    plt.imshow(sample)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.title('64 samples from MNIST')\n",
    "    plt.show()\n",
    "\n",
    "    # print('Labels:', dataset.train_labels[:64].numpy())\n",
    "def draw_after_epoch(samples, epoch):\n",
    "    #print(len(samples), samples[0][0])\n",
    "    w, h = 10, 10\n",
    "    ax = []\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    rows, columns = 5, 4\n",
    "    for i in range(1, columns*rows + 1):\n",
    "        ax.append(fig.add_subplot(rows, columns, i))\n",
    "        ax[-1].set_title(f\"Epoch {epoch}, example {int((i-1)//2 + 1)}\")\n",
    "        idx = (i - 1) // 2\n",
    "        img = samples[0][i%2][idx].permute(1,2,0)\n",
    "        \n",
    "        print(img.shape)\n",
    "        plt.imshow(img.detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHpS_TsdP6xA"
   },
   "source": [
    "# Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2zEStFVP81v"
   },
   "outputs": [],
   "source": [
    "# UTILS\n",
    "\n",
    "def save_checkpoint(optimizer, model, epoch, filename):\n",
    "    checkpoint_dict = {\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(checkpoint_dict, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(optimizer, model, filename):\n",
    "    checkpoint_dict = torch.load(filename)\n",
    "    epoch = checkpoint_dict['epoch']\n",
    "    model.load_state_dict(checkpoint_dict['model'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint_dict['optimizer'])\n",
    "    return epoch\n",
    "\n",
    "def draw_losses(train_losses, test_losses):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(epochs, train_losses, '-o', label='Training loss')\n",
    "    plt.plot(epochs, test_losses, '-o', label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.title('Learning curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTt8-jvHP9dC"
   },
   "source": [
    "# AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GSHltwvP9qF"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(48 * 48 * 3, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 48 * 48 * 3),\n",
    "            nn.Sigmoid())\n",
    "        self.classify = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        dec = self.decoder(enc)\n",
    "        return dec, enc #self.classify(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_M2lAhyz2UBJ"
   },
   "source": [
    "# CONV AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXsWxghw2Vgr"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=2, padding=1),  # b, 16, 10, 10\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ELU(0.1),\n",
    "        )\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(0.1),\n",
    "        )\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(0.1)\n",
    "        )\n",
    "        self.dec0 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(0.1)\n",
    "        )\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 2, stride=2),  # b, 16, 5, 5\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ELU(0.1),\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 3, 2, stride=2),  # b, 8, 15, 15\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        enc = x\n",
    "        x = self.dec1(x)\n",
    "        dec = self.dec2(x)\n",
    "        return dec, enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHlm29raVvqL"
   },
   "source": [
    "# Better CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10nmKrTuVv7E"
   },
   "outputs": [],
   "source": [
    "class HugeConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HugeConvAutoencoder, self).__init__()\n",
    "        self.enc_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32,32,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32,64,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64,64,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        self.dec_layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64,64,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32,32,3,2,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32,3,3,2,1,1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc = self.enc_layer1(x)\n",
    "        dec = self.dec_layer2(enc)\n",
    "        return dec, enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5AzWEMWxzWMU"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxOatAg_qZ6_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_result(images: np.ndarray, out_path: str):\n",
    "    assert images.shape == (400, 3, 48, 48)\n",
    "    \n",
    "    flat_img = images.reshape(400, -1)\n",
    "    n_rows = np.prod(images.shape)\n",
    "    \n",
    "    y_with_id = np.concatenate([np.arange(n_rows).reshape(-1, 1), flat_img.reshape(n_rows, 1)], axis=1)\n",
    "    np.savetxt(out_path, y_with_id, delimiter=\",\", fmt=['%d', '%.4f'], header=\"id,expetced\", comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEF7u6kFQCBw"
   },
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DEEC7hyQCNs"
   },
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    train_loss = MovingAverage()\n",
    "    criterion = nn.MSELoss()\n",
    "    samples = []\n",
    "    \n",
    "    for batch_idx, (clean, distorted) in enumerate(train_loader):\n",
    "        if batch_idx % 10 == 0: print(f\"batch {batch_idx}\")\n",
    "        clean, distorted = clean.to(device), distorted.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(distorted)\n",
    "        \n",
    "        loss = criterion(clean, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        train_loss.update(loss)\n",
    "    \n",
    "    return samples, train_loss.value\n",
    "    \n",
    "def test(args, model, device, test_loader):\n",
    "    criterion = nn.MSELoss()\n",
    "    test_loss = RunningAverage()\n",
    "    correct, all_examples = 0, 0\n",
    "    samples = []\n",
    "    all_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (clean, distorted) in enumerate(test_loader):\n",
    "            if batch_idx % 5 == 0: print(f\"batch {batch_idx}\")\n",
    "            clean, distorted = clean.to(device), distorted.to(device)\n",
    "            #clean = clean.view(clean.shape[0], -1)\n",
    "            #distorted = distorted.view(distorted.shape[0], -1)\n",
    "            output, classification = model(distorted)\n",
    "            if batch_idx == 0:\n",
    "                samples.append((distorted, output))\n",
    "                #if batch_idx == 0: print(output[0])\n",
    "                #samples.append((distorted.view(3,48,48), output.view(3,48,48)))\n",
    "            loss = criterion(clean, output)\n",
    "            all_loss += loss\n",
    "            test_loss.update(loss)\n",
    "    \n",
    "    print(f\"Summarized loss is {all_loss}\")\n",
    "    return samples, test_loss.value \n",
    "\n",
    "def get_test_results(data_loader, model):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, distorted in enumerate(data_loader):\n",
    "            distorted = distorted.to(device)\n",
    "            output, _ = model(distorted)\n",
    "            results.append(output)\n",
    "    \n",
    "    return torch.stack(results)\n",
    "  \n",
    "def main_loop(args, device, train_loader, val_loader, test_loader):\n",
    "    #model = AutoEncoder().to(device)\n",
    "    #model = ConvAutoencoder().to(device)\n",
    "    model = HugeConvAutoencoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    min_loss = 1000.0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        _, train_loss = train(args, model, device, train_loader, optimizer, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        samples, test_loss = test(args, model, device, val_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        if min_loss > test_loss:\n",
    "            min_loss = test_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            \n",
    "        if not epoch % args.frequency:\n",
    "            draw_after_epoch(samples, epoch)\n",
    "    \n",
    "    draw_losses(train_losses, test_losses)\n",
    "    test_model = HugeConvAutoencoder().to(device)\n",
    "    test_model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return get_test_results(test_loader, test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WijrOHdtu9dR"
   },
   "source": [
    "# MAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdgOed0yQJH_"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':    \n",
    "    args = edict({\n",
    "        'train_batch_size': 64,4/cAF29EwM0ZB76kbngNMhuN_tUZELv95NCX1B61iNkSrAPKNEagaOr5M\n",
    "        'test_batch_size': 100,\n",
    "        'epochs': 40,\n",
    "        'lr': 0.0002,\n",
    "        'momentum': 0.5, \n",
    "        'no_cuda': False,\n",
    "        'valid_percent': 0.1,\n",
    "        'seed': 7,\n",
    "        'log_interval': 50,\n",
    "        'save_model': False,\n",
    "        'frequency': 3,\n",
    "    })\n",
    "    \n",
    "#     clean_data, dist_data = get_clean_and_distorted_examples()\n",
    "#     test_data = get_test_examples()\n",
    "#     print(clean_data.shape, dist_data.shape, test_data.shape)\n",
    "    clean_path = os.path.join(data_dir, 'clean.pt')\n",
    "    dist_path = os.path.join(data_dir, 'dist.pt')\n",
    "    test_path = os.path.join(data_dir, 'test.pt')\n",
    "    \n",
    "#     torch.save(clean_data, clean_path)\n",
    "#     torch.save(dist_data, dist_path)\n",
    "#     torch.save(test_data, test_path)\n",
    "    clean_data = torch.load(clean_path)#, map_location={'cpu:', 'cuda:0'})\n",
    "    dist_data = torch.load(dist_path)#, map_location=lambda storage, loc: storage.cuda(0))\n",
    "    test_data = torch.load(test_path)#, map_location=lambda storage, loc: storage.cuda(0))\n",
    "    print(clean_data.shape, dist_data.shape, test_data.shape)\n",
    "\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    \n",
    "    torch.manual_seed(args.seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    #train_loader, val_loader, test_loader = get_dataloaders(args, True, clean_data, dist_data, test_data)\n",
    "    #test_results = main_loop(args, device, train_loader, val_loader, test_loader)\n",
    "    test_results = test_results.reshape(400, 3, 48, 48)\n",
    "    save_result(test_results.cpu().numpy(), results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VFIAfSW5pnJ"
   },
   "source": [
    "# Fast results generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1WrBlZ_4o96"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(data_dir, 'best_checkpoint.pkl')\n",
    "\n",
    "test_path = os.path.join(data_dir, 'test.pt')\n",
    "test_data = torch.load(test_path)\n",
    "\n",
    "test_dataset = TestDataset(test_data)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_model = HugeConvAutoencoder().to(device)\n",
    "test_model.load_state_dict(torch.load(checkpoint_path))\n",
    "test_results = get_test_results(test_loader, test_model)\n",
    "test_results = test_results.reshape(400, 3, 48, 48)\n",
    "save_result(test_results.cpu().numpy(), results_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "C4dmZo93O73T",
    "c3u8qQp4PJaL",
    "EVAmSYmJPMVM",
    "wHpS_TsdP6xA",
    "jTt8-jvHP9dC"
   ],
   "name": "Best.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
