{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia 2_MLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lhZfjpR77W2e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab. 2 Multi Layered Networks\n",
        "\n",
        "### Ładowanie danych\n",
        "\n",
        "PyTroch, a właściwie pakiet `torchvision` udostępnia parę przydatnych rzeczy, z których skorzystamy na dzisiejszych zajęciach.\n",
        "\n",
        "Zacznijmy od ściąganie i ładowania danych, w [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html) znajdziemy popularne datasety, zajmiemy się dzisiaj MNISTem."
      ]
    },
    {
      "metadata": {
        "id": "Mku0UNM_7W2g",
        "colab_type": "code",
        "outputId": "876c9310-f167-450b-cb4f-d5625178e164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "train_data = MNIST(root='.', download=True, train=True)\n",
        "test_data = MNIST(root='.', download=True, train=False)\n",
        "\n",
        "train_data[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F2AF2B06668>, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "xK8angP57W2k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Oprócz tego z samego `torcha` możemy skorzystać z [`DataLoadera`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), który załatwia za nas sporo przydatnych rzeczy typu shufflowanie i batchowanie danych."
      ]
    },
    {
      "metadata": {
        "id": "6NNSiOsV7W2m",
        "colab_type": "code",
        "outputId": "8e3a4a9c-028d-42fb-f10e-e304fd80a3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "datas = torch.div(train_data.data.type(torch.float), 255)\n",
        "mi, st = datas.mean(), datas.std()\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[mi], std=[st], inplace=True),\n",
        "    transforms.Lambda(lambda x: x.view(784))\n",
        "])\n",
        "\n",
        "\n",
        "train_data = [(img_transform(img[0]), img[1]) for img in train_data]\n",
        "test_data = [(img_transform(img[0]), img[1]) for img in test_data]\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64)\n",
        "\n",
        "for x, y in train_loader:\n",
        "    print(x.shape)\n",
        "    print(x.dtype)\n",
        "    print(y)\n",
        "    break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 784])\n",
            "torch.float32\n",
            "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
            "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
            "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "By6m_RxQ7W2q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wygląda na to, że aż tak bardzo za darmo wszystkiego nie dostaniemy, klasa `MNIST` zwraca nam dane w postaci obiektów [PILa](https://pillow.readthedocs.io/en/stable/). Musimy coś z tym zrobić.\n",
        "\n",
        "## Zadanie 1.\n",
        "1. Za pomocą [`transformerów`](https://pytorch.org/docs/stable/torchvision/transforms.html) przerobić powyższy kod tak aby zadziałał.  \n",
        "**HINT**: sprawdzić jakie argumenty przyjmuje klasa `MNIST`.\n",
        "2. Policzyć średnią i odchylenie standardowe wartości pojedynczego piksela dla całego zbioru trenującego i użyć ich do znormalizowania danych trenujących.  \n",
        "**HINT**: Tutaj torchvision też powinien nam to ułatwić.\n",
        "3. Zmienić \"kształt\" jednego przykładu z `28x28` na `784`.  \n",
        "**HINT**: [`Lambda`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Lambda)\n",
        "\n",
        "Uwaga: zwrócić uwagę co dokładnie robią używane _transformery_!\n",
        "\n",
        "## Zadanie 2.\n",
        "\n",
        "Ręcznie zaimplementować prostą sieć z jedną warstwą ukrtyą. Sieć ma mieć:\n",
        "1. Jedną warstwę ukrytą rozmiaru 500 z wagami zainicjalizowanymi ze standardowego rozkładu normalnego.\n",
        "2. Warstwa przy obu operacjach ma mieć uczone _biasy_ zainicjalizowane na 0.\n",
        "\n",
        "**HINT**: Do rozkładu normalnego najlepiej użyć [`torch.randn`](https://pytorch.org/docs/stable/torch.html#torch.randn). Sprawdzić jakie ważne argumenty ta funkcja przyjmuje!\n",
        "\n",
        "Należy oprócz tego zaimplementować pętlę uczenia z użyciem PyTorchowej funkcji kosztu _cross entropy_ i optymalizatora SGD."
      ]
    },
    {
      "metadata": {
        "id": "VcigOhW-7W2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNetwork(object):\n",
        "    \"\"\"\n",
        "    Simple 1-hidden layer linear neural network\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size, inp, hidd, out):\n",
        "        \"\"\"\n",
        "        Initialize network's weights \n",
        "        \"\"\"\n",
        "        \n",
        "        self.weight_1: torch.Tensor = torch.randn(inp, hidd, requires_grad=True)\n",
        "        self.bias_1: torch.Tensor = torch.randn(batch_size, 1, requires_grad=True)\n",
        "        self.bias_1.data.fill_(0)\n",
        "\n",
        "        self.weight_2: torch.Tensor = torch.randn(hidd, out, requires_grad=True)\n",
        "        self.bias_2: torch.Tensor = torch.randn(batch_size, 1, requires_grad=True)\n",
        "        self.bias_2.data.fill_(0)\n",
        "        \n",
        "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the network\n",
        "        \"\"\"\n",
        "        a: torch.Tensor = torch.mm(x, self.weight_1)\n",
        "        a: torch.Tensor = a + self.bias_1.expand_as(a)\n",
        "        a: torch.Tensor = torch.mm(a, self.weight_2)\n",
        "        a: torch.Tensor = a + self.bias_2.expand_as(a)        \n",
        "        return a\n",
        "    \n",
        "    def parameters(self) -> List[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Returns all trainable parameters \n",
        "        \"\"\"\n",
        "        return [self.weight_1, self.bias_1, self.weight_2, self.bias_2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "wmEd2iE17W2u",
        "colab_type": "code",
        "outputId": "6118384c-1d45-44ef-e73e-d6fefd6e9c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torch import optim\n",
        "\n",
        "# some hyperparams\n",
        "batch_size: int = 64\n",
        "input_dim: int = 784\n",
        "hidden_dim: int = 500\n",
        "output_dim: int = 10\n",
        "epoch: int = 3\n",
        "lr: float = 0.01\n",
        "momentum: float = 0.9\n",
        "\n",
        "# prepare data loaders, base don the already loaded datasets\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# initialize the model\n",
        "model: CustomNetwork = CustomNetwork(batch_size, input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# initialize the optimizer\n",
        "optimizer: torch.optim.Optimizer = optim.SGD(model.parameters(), lr, momentum)\n",
        "  \n",
        "# training loop\n",
        "for e in range(epoch):\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        if x.shape[0] != batch_size: continue\n",
        "        # reset the gradients from previouis iteration\n",
        "        optimizer.zero_grad()\n",
        "        # pass through the network\n",
        "        output: torch.Tensor = model(x)\n",
        "        # calculate loss\n",
        "        loss: torch.Tensor = cross_entropy(output, y)\n",
        "        # backward pass thorught the network\n",
        "        loss.backward()\n",
        "        # apply the gradients\n",
        "        optimizer.step()\n",
        "        \n",
        "        # log the loss value\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Epoch {e} iter {i+1}/{len(train_data) // batch_size} loss: {loss.item()}\", end=\"\\r\")\n",
        "            \n",
        "    # at the end of an epoch run evaluation on the test set\n",
        "    with torch.no_grad():\n",
        "        # initialize the number of correct predictions\n",
        "        correct: int = 0 \n",
        "        for i, (x, y) in enumerate(test_loader):\n",
        "            if x.shape[0] != batch_size: continue\n",
        "\n",
        "            output: torch.Tensor = model(x)\n",
        "            correct += (torch.max(output, 1)[1].view(batch_size) == y).sum().item()\n",
        "\n",
        "        print(f\"\\nTest accuracy: {correct / len(test_data)}\")\n",
        "\n",
        "        \n",
        "# this is your test\n",
        "assert correct / len(test_data) > 0.8, \"Subject to random seed you should be able to get >80% accuracy\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test accuracy: 0.8276\n",
            "\n",
            "Test accuracy: 0.8513\n",
            "\n",
            "Test accuracy: 0.8434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sqBev_Dm7W2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Zadanie 3.\n",
        "\n",
        "1. Przepisać całą sieć do PyTorcha używając [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), [`torch.nn.Linear`](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear).\n",
        "2. Dodać [nieliniowe aktywacje](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) i dodatkową warstwę, tak aby wyciągnąć przynajmniej 95% testowego accuracy w 3 epoki."
      ]
    },
    {
      "metadata": {
        "id": "zkolCf8OFLOU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pu"
      ]
    },
    {
      "metadata": {
        "id": "QEq5iiB47W2z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TorchNetwork(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Simple 2-hidden layer non-linear neural network\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size, input_dim, hidden_dim, hidden_dim2, output_dim):\n",
        "        super(TorchNetwork, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer2 = nn.Linear(hidden_dim, hidden_dim2)\n",
        "        self.layer3 = nn.Linear(hidden_dim2, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ohycfr3g7W23",
        "colab_type": "code",
        "outputId": "892d54f2-efbb-4ce9-bdcb-e3d1a507c9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "# some hyperparams\n",
        "batch_size: int = 64\n",
        "epoch: int = 3\n",
        "lr: float = 0.01\n",
        "momentum: float = 0.9\n",
        "hidden_dim: int = 500\n",
        "hidden_dim2: int = 200 \n",
        "input_dim: int = 784\n",
        "output_dim: int = 10\n",
        "\n",
        "# prepare data loaders, base don the already loaded datasets\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# initialize the model\n",
        "model: TorchNetwork = TorchNetwork(batch_size, input_dim, hidden_dim, hidden_dim2, output_dim)\n",
        "  \n",
        "# initialize the optimizer\n",
        "optimizer: torch.optim.Optimizer = optim.SGD(model.parameters(), lr, momentum)\n",
        "\n",
        "# training loop\n",
        "for e in range(epoch):\n",
        "    tr_loss = 0\n",
        "    te_loss = 0\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        model.zero_grad()\n",
        "        output: torch.Tensor = model(x)\n",
        "        loss: torch.Tensor = cross_entropy(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Epoch {e} iter {i+1}/{len(train_data) // batch_size} loss: {loss.item()}\", end='\\r')\n",
        "    # at the end of an epoch run evaluation on the test set\n",
        "    with torch.no_grad():\n",
        "        correct: int = 0\n",
        "        for i, (x, y) in enumerate(test_loader):\n",
        "            output: torch.Tensor = model(x)\n",
        "            correct += (torch.max(output, 1)[1].view(y.shape[0]) == y).sum().item()       \n",
        "\n",
        "        print(f\"\\nTest accuracy: {correct / len(test_data)}\")\n",
        "            \n",
        "# this is your test\n",
        "assert correct / len(test_data) > 0.95, \"Subject to random seed you should be able to get >95% accuracy\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test accuracy: 0.9559\n",
            "\n",
            "Test accuracy: 0.9704\n",
            "\n",
            "Test accuracy: 0.9731\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}